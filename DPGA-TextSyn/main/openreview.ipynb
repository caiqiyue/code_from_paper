{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import csv\n",
    "import os\n",
    "from tqdm.notebook import tqdm,trange\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy.linalg import sqrtm\n",
    "from numpy import iscomplexobj, trace, cov\n",
    "from utils.compute_mauve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample_length():\n",
    "    with open(length_path, 'r') as f:\n",
    "        length_list = json.load(f)\n",
    "    f.close()\n",
    "    random_length = np.random.choice(length_list)\n",
    "    return random_length\n",
    "\n",
    "def random_sample_subcategory(c):\n",
    "    with open(subcategory_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    f.close()\n",
    "    random_subcategory = random.choices(data[c]['Subcategories'], weights=data[c]['Probabilities'], k=1)[0]\n",
    "    return random_subcategory\n",
    "\n",
    "def splitstr(text,strr):\n",
    "    return text.split(strr)\n",
    "\n",
    "def save_listdata_to_json(data, path):\n",
    "    filedir = os.path.dirname(path)\n",
    "    if not os.path.exists(filedir):\n",
    "        os.makedirs(filedir)\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        file.close()\n",
    "    else:\n",
    "        with open(path, 'r+', encoding='utf-8') as file:\n",
    "            file_data = json.load(file)  \n",
    "            file_data.extend(data) \n",
    "            file.seek(0)  \n",
    "            json.dump(file_data, file, ensure_ascii=False, indent=4)\n",
    "        file.close()\n",
    "\n",
    "def get_length(text):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def json2csv(json_file,label_file,csv_file):\n",
    "\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    with open(label_file, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "        writer.writerow(['text','label1','label2'])\n",
    "        for item, label in zip(data,labels):\n",
    "            clean_item = str(item)\n",
    "            label1 = label.split('_')[0]\n",
    "            label2 = label.split('_')[1]\n",
    "            writer.writerow([clean_item,label1,label2]) \n",
    "\n",
    "\n",
    "def get_path(index, category, extension):\n",
    "    return result_path + 'epoch_' + str(index) + '_' + category + '.' + extension\n",
    "\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def transfer_blank(text,p):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    text_token = encoding.encode(text)\n",
    "    new_text_token = [encoding.encode('_')[0] if random.random() < p else x for x in text_token]\n",
    "    return encoding.decode(new_text_token)\n",
    "\n",
    "def aggregate_data(index,lst,num):\n",
    "    data = []\n",
    "    for item in lst:\n",
    "        data.extend(load_json_data(get_path(index, item, 'json')))\n",
    "    chunks = [data[i:i + num] for i in range(0, len(data), num)]\n",
    "    data_all = list(itertools.chain.from_iterable(zip(*chunks)))\n",
    "    save_listdata_to_json(data_all, get_path(index+1,'all','json'))\n",
    "\n",
    "def cross_choice(data):\n",
    "    lst_text = np.random.choice(data, 2, replace=False).tolist()\n",
    "    return random.choice([lst_text, lst_text[::-1]])\n",
    "\n",
    "def mutate_choice(data):\n",
    "    return random.choice(data)\n",
    "\n",
    "def generate_choice(data):\n",
    "    return np.random.choice(data, min(3,len(data)), replace=False).tolist()\n",
    "\n",
    "def count_selected_indices(part_sizes, selected_indices):\n",
    "    count_selected = [0] * len(part_sizes)\n",
    "    start_index = 0\n",
    "    for i, size in enumerate(part_sizes):\n",
    "        end_index = start_index + size\n",
    "        count_selected[i] = sum(1 for index in selected_indices if start_index <= index < end_index)\n",
    "        start_index = end_index\n",
    "    return count_selected\n",
    "\n",
    "def calculate_fid(embeddings1, embeddings2):\n",
    "    mu1, sigma1 = embeddings1.mean(axis=0), cov(embeddings1, rowvar=False)\n",
    "    mu2, sigma2 = embeddings2.mean(axis=0), cov(embeddings2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2) ** 2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    print(\"FID: \", fid)\n",
    "    return fid\n",
    "\n",
    "def calculate_all_metrics(synthetic_embeddings, original_embeddings):\n",
    "    method_name = \"\"\n",
    "    p_feats = synthetic_embeddings  \n",
    "    q_feats = original_embeddings\n",
    "    result = compute_mauve(p_feats, q_feats)\n",
    "    print(\"MAUVE: \", result.mauve)\n",
    "\n",
    "\n",
    "def self_similarity(embeddings):\n",
    "    similarity_matrix = cosine_similarity(embeddings.unsqueeze(0), embeddings.unsqueeze(1), dim=2)\n",
    "    mask = torch.ones_like(similarity_matrix) - torch.eye(similarity_matrix.size(0), device=similarity_matrix.device)\n",
    "    masked_similarity_matrix = similarity_matrix * mask\n",
    "    max_value, flat_index = masked_similarity_matrix.view(-1).max(0)  \n",
    "    max_index = (flat_index // masked_similarity_matrix.size(1), flat_index % masked_similarity_matrix.size(1))\n",
    "    average_similarity = masked_similarity_matrix.sum() / mask.sum()\n",
    "    print(f\"Average similarity of the dataset: {average_similarity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_population(syn_list, max_workers, combined_label, client):\n",
    "    def get_initdata(label):\n",
    "        label1 = label.split(\"_\")[0]\n",
    "        label2 = label.split(\"_\")[1]\n",
    "        success = False\n",
    "        length = random_sample_length()\n",
    "        subcategory = random_sample_subcategory(label1)\n",
    "        closest_ret = \"\"\n",
    "        closest_diff = float('inf')\n",
    "        n=0\n",
    "        while not success and n < 3:\n",
    "            try:\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=1.2,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"xxxxxxxxxxxxxxxxxx\"},\n",
    "                        {\"role\": \"user\", \"content\": \"xxxxxxxxxxxxxxxxxxxxx\"},\n",
    "                    ]\n",
    "                )\n",
    "                ret = completion.choices[0].message.content\n",
    "                actual_length = get_length(ret)\n",
    "                length_diff = abs(actual_length - length)\n",
    "\n",
    "                if length * 0.8 <= actual_length <= length * 1.2:\n",
    "                    success = True\n",
    "                    return ret\n",
    "                else:\n",
    "                    if length_diff < closest_diff:\n",
    "                        closest_ret = ret\n",
    "                        closest_diff = length_diff\n",
    "                    n += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "        return closest_ret\n",
    "    label_list = []\n",
    "    syn_num = sum(syn_list)\n",
    "    for j in range(len(syn_list)):\n",
    "        for k in range(syn_list[j]):\n",
    "            label_list.append(combined_label[j])\n",
    "    if not os.path.exists(get_path(1,'all_label','json')):\n",
    "        save_listdata_to_json(label_list, get_path(1,'all_label','json'))\n",
    "\n",
    "    results = [None] * len(label_list)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_initdata, label): i for i, label in enumerate(label_list)}\n",
    "\n",
    "        with tqdm(total=syn_num, desc=\"get_initial_population\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                index = futures[future]\n",
    "                results[index] = result  \n",
    "                pbar.update(1)\n",
    "\n",
    "    save_listdata_to_json(results, get_path(1, 'all', 'json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_elite_choice_per_class(train_embeddings, embeddings_pt, class_indices, num_choice, sigma=None, threshold=0.80):\n",
    "    train_embeddings = train_embeddings.to('cuda')\n",
    "    embeddings_pt = embeddings_pt[class_indices].to('cuda')\n",
    "    class_indices = torch.tensor(class_indices).long().to('cuda')\n",
    "    distances = torch.cdist(train_embeddings, embeddings_pt)\n",
    "    closest_indices = torch.argmin(distances, dim=1)\n",
    "    votes = torch.bincount(closest_indices, minlength=embeddings_pt.size(0))\n",
    "    \n",
    "    if sigma is not None and sigma > 0:\n",
    "        print(\"Adding noise with sigma =\", sigma)\n",
    "        noise = torch.normal(0, sigma, size=votes.shape, device=votes.device)\n",
    "        votes += noise\n",
    "        votes = torch.clamp(votes, min=0)\n",
    "    else:\n",
    "        pass\n",
    "    top_values, top_indices = torch.topk(votes, embeddings_pt.shape[0])\n",
    "\n",
    "    selected_indices = []\n",
    "    temp=0\n",
    "    current_threshold = threshold\n",
    "\n",
    "    while len(selected_indices) < num_choice:\n",
    "        \n",
    "        for idx in top_indices:\n",
    "            if len(selected_indices) >= num_choice:\n",
    "                break\n",
    "            if idx.item() in selected_indices:\n",
    "                continue\n",
    "            if selected_indices:\n",
    "                selected_embeddings = embeddings_pt[selected_indices]\n",
    "                similarity = F.cosine_similarity(embeddings_pt[idx].unsqueeze(0), selected_embeddings)\n",
    "                if torch.any(similarity >= current_threshold):\n",
    "                    continue\n",
    "\n",
    "            selected_indices.append(idx.item())\n",
    "\n",
    "        if len(selected_indices) < num_choice:\n",
    "            current_threshold = round(current_threshold + 0.01, 2)\n",
    "        temp = len(selected_indices)\n",
    "    \n",
    "    selected_indices = class_indices[selected_indices].tolist()\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def select_tensors_by_probability(train_embeddings, probability):\n",
    "    bernoulli_samples = torch.bernoulli(torch.full((train_embeddings.size(0),), probability))\n",
    "    selected_tensors = train_embeddings[selected_indices]\n",
    "    return selected_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate1(text):\n",
    "    length = get_length(text)\n",
    "    blank = transfer_blank(text,p)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=1.2,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"xxx\"},\n",
    "                    {\"role\": \"user\", \"content\": \"xxx\"},\n",
    "                ]\n",
    "            )\n",
    "            ret = completion.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "            if abs(length-get_length(ret)) / length > 0.8:\n",
    "                continue\n",
    "            success = True\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate2(text, p=0.5):\n",
    "    length = get_length(text)\n",
    "\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=1.2,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"xxx\"},\n",
    "                    {\"role\": \"user\", \"content\": \"xxx\"},\n",
    "                ]\n",
    "            )\n",
    "            ret = completion.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "            if abs(length-get_length(ret)) / length > 0.8:\n",
    "                continue\n",
    "            success = True\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(text):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            length = get_length(text)\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=1.2,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"xxx\"},\n",
    "                    {\"role\": \"user\", \"content\": \"xxx\"},\n",
    "                ]\n",
    "            )\n",
    "            ret = completion.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "            if abs(length-get_length(ret)) / length > 0.8:\n",
    "                continue\n",
    "            success = True\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(label):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            length = random_sample_length()\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                temperature=1.2,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"xxx\"},\n",
    "                    {\"role\": \"user\", \"content\": \"xxx\"},\n",
    "                ]\n",
    "            )\n",
    "            ret = completion.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "            if get_length(ret) < 80 or get_length(ret) > 1000:\n",
    "                continue\n",
    "\n",
    "            success = True\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_num = 2000\n",
    "syn_num = 10000\n",
    "max_workers = 1000\n",
    "T = 10\n",
    "sigma = 0 #eps=inf\n",
    "sample_p = 1\n",
    "filter_p = 1\n",
    "result_path = '../data/openreview/dpga_result/xxx/'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "if sample_p == 1:\n",
    "    train_embeddings = torch.load(train_emb_path)\n",
    "    df = pd.read_csv(train_csv_path, sep=',')\n",
    "else:\n",
    "    train_embeddings, df = select_tensors_by_probability(torch.load(train_emb_path), pd.read_csv(train_csv_path, sep=','), sample_p)\n",
    "\n",
    "df['combined_label'] = df['label1'].astype(str) + \"_\" + df['label2'].astype(str)\n",
    "combined_label = {index: label for index, label in enumerate(list(dict.fromkeys(df['combined_label'].values)))}\n",
    "with open(class_path, 'r') as f:\n",
    "    class_list = json.load(f)\n",
    "f.close()\n",
    "elite_list = allocate_elite_numbers(elite_num, class_list)\n",
    "syn_list = [x*5 for x in elite_list]\n",
    "\n",
    "combined_label_inv = {label: index for index, label in enumerate(list(dict.fromkeys(df['combined_label'].values)))}\n",
    "unique_labels = list(combined_label_inv.keys())\n",
    "if len(unique_labels) != len(class_list):\n",
    "    exit(\"The number of unique labels does not match the number of elite numbers!\")\n",
    "\n",
    "for i in range(1,T+1):\n",
    "    client = OpenAI(base_url=\"xxxx\",api_key=\"sk-xxxxxx\")\n",
    "    if i == 1:\n",
    "        if not os.path.exists(get_path(i, 'all', 'json')):\n",
    "            get_initial_population(syn_list, max_workers, combined_label, client)\n",
    "    data_all = load_json_data(get_path(i,'all','json'))\n",
    "    if not os.path.exists(get_path(i, 'all_emb', 'pt')) or len(torch.load(get_path(i,'all_emb','pt')))!=len(data_all):\n",
    "        get_embeddings(i,'all')\n",
    "\n",
    "    embeddings_pt = torch.load(get_path(i,'all_emb','pt'))\n",
    "    labels_list = load_json_data(get_path(1,'all_label','json'))\n",
    "\n",
    "    selected_indices = []\n",
    "    for class_label, k in zip(unique_labels, elite_list):\n",
    "        train_class_indices = [i for i, label in enumerate(df['combined_label'].values) if label == class_label]\n",
    "        class_indices = [i for i, label in enumerate(labels_list) if label == class_label]\n",
    "        selected_indices.extend(filter_elite_choice_per_class(train_embeddings[train_class_indices], embeddings_pt, class_indices, k, sigma, filter_p))\n",
    "\n",
    "    if not os.path.exists(get_path(i,'elite','json')):\n",
    "        save_listdata_to_json([data_all[indice] for indice in selected_indices],get_path(i,'elite','json'))#保存精英集\n",
    "        save_listdata_to_json([labels_list[indice] for indice in selected_indices],get_path(i,'elite_label','json'))\n",
    "        json2csv(get_path(i,'elite','json'),get_path(i,'elite_label','json'),get_path(i,'elite','csv'))\n",
    "\n",
    "    if not os.path.exists(get_path(i, 'elite_emb', 'pt')):\n",
    "        elite_embeddings_pt = embeddings_pt[selected_indices]\n",
    "        torch.save(elite_embeddings_pt,get_path(i,'elite_emb','pt'))\n",
    "\n",
    "    calculate_all_metrics(torch.load(get_path(i,'elite_emb','pt')).cpu().numpy(),torch.load(train_emb_path).cpu().numpy())\n",
    "    calculate_fid(torch.load(get_path(i,'elite_emb','pt')).cpu().numpy(),torch.load(train_emb_path).cpu().numpy())\n",
    "    if i == 1: \n",
    "        break\n",
    "\n",
    "    results_mutate = [None] * elite_num\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor_mutate:\n",
    "        futures_mutate = {executor_mutate.submit(mutate1, data_all[indice],labels_list[indice]): index for index, indice in enumerate(selected_indices)}\n",
    "        with tqdm(total=elite_num, desc=\"mutate1\") as pbar:\n",
    "            for future_mutate in as_completed(futures_mutate):\n",
    "                result_mutate = future_mutate.result()  \n",
    "                index = futures_mutate[future_mutate] \n",
    "                results_mutate[index] = result_mutate  \n",
    "                pbar.update(1)  \n",
    "    save_listdata_to_json(results_mutate, get_path(i, 'mutate1', 'json'))\n",
    "\n",
    "    results_mutate = [None] * elite_num\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor_mutate:\n",
    "        futures_mutate = {executor_mutate.submit(mutate2, data_all[indice],labels_list[indice]): index for index, indice in enumerate(selected_indices)}\n",
    "        with tqdm(total=elite_num, desc=\"mutate2\") as pbar:\n",
    "            for future_mutate in as_completed(futures_mutate):\n",
    "                result_mutate = future_mutate.result() \n",
    "                index = futures_mutate[future_mutate]  \n",
    "                results_mutate[index] = result_mutate \n",
    "                pbar.update(1) \n",
    "    save_listdata_to_json(results_mutate, get_path(i, 'mutate2', 'json'))\n",
    "\n",
    "    results_cross = [None] * elite_num\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor_cross:\n",
    "\n",
    "        futures_cross = {executor_cross.submit(cross, data_all[indice],labels_list[indice]): index for index, indice in enumerate(selected_indices)}\n",
    "        with tqdm(total=elite_num, desc=\"cross\") as pbar:\n",
    "            for future_cross in as_completed(futures_cross):\n",
    "                result_cross = future_cross.result()  \n",
    "                index = futures_cross[future_cross]  \n",
    "                results_cross[index] = result_cross  \n",
    "                pbar.update(1) \n",
    "    save_listdata_to_json(results_cross, get_path(i, 'cross', 'json'))\n",
    "\n",
    "    results_generate = [None] * elite_num\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor_generate:\n",
    "\n",
    "        futures_generate = {executor_generate.submit(generate, data_all[indice],labels_list[indice]): index for index, indice in enumerate(selected_indices)}\n",
    "        with tqdm(total=elite_num, desc=\"generate\") as pbar:\n",
    "            for future_generate in as_completed(futures_generate):\n",
    "                result_generate = future_generate.result() \n",
    "                index = futures_generate[future_generate] \n",
    "                results_generate[index] = result_generate \n",
    "                pbar.update(1)  \n",
    "    save_listdata_to_json(results_generate, get_path(i, 'generate', 'json'))\n",
    "    \n",
    "    aggregate_data(i,['elite','mutate1','mutate2','cross','generate']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
